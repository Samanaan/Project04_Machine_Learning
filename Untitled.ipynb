{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0c3dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:04:27.170117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5049f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>month_year</th>\n",
       "      <th>qty_sold</th>\n",
       "      <th>total_price</th>\n",
       "      <th>freight_price</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>product_rating</th>\n",
       "      <th>no_customers</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>comp1_price</th>\n",
       "      <th>comp1_prod_rating</th>\n",
       "      <th>comp1_freight_price</th>\n",
       "      <th>comp2_price</th>\n",
       "      <th>comp2_prod_rating</th>\n",
       "      <th>comp2_freight_price</th>\n",
       "      <th>comp3_price</th>\n",
       "      <th>comp3_prod_rating</th>\n",
       "      <th>comp3_freight_price</th>\n",
       "      <th>lag_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bed1</td>\n",
       "      <td>bed_bath_table</td>\n",
       "      <td>01-05-2017</td>\n",
       "      <td>1</td>\n",
       "      <td>45.95</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>89.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>15.011897</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.760000</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>45.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bed1</td>\n",
       "      <td>bed_bath_table</td>\n",
       "      <td>01-06-2017</td>\n",
       "      <td>3</td>\n",
       "      <td>137.85</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>89.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14.769216</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>4.4</td>\n",
       "      <td>21.322000</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>45.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bed1</td>\n",
       "      <td>bed_bath_table</td>\n",
       "      <td>01-07-2017</td>\n",
       "      <td>6</td>\n",
       "      <td>275.70</td>\n",
       "      <td>14.840000</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>89.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13.993833</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>4.4</td>\n",
       "      <td>22.195932</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.840000</td>\n",
       "      <td>45.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bed1</td>\n",
       "      <td>bed_bath_table</td>\n",
       "      <td>01-08-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>183.80</td>\n",
       "      <td>14.287500</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>89.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14.656757</td>\n",
       "      <td>199.509804</td>\n",
       "      <td>4.4</td>\n",
       "      <td>19.412885</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.287500</td>\n",
       "      <td>45.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bed1</td>\n",
       "      <td>bed_bath_table</td>\n",
       "      <td>01-09-2017</td>\n",
       "      <td>2</td>\n",
       "      <td>91.90</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>89.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>18.776522</td>\n",
       "      <td>163.398710</td>\n",
       "      <td>4.4</td>\n",
       "      <td>24.324687</td>\n",
       "      <td>45.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>45.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id product_category_name  month_year  qty_sold  total_price  \\\n",
       "0       bed1        bed_bath_table  01-05-2017         1        45.95   \n",
       "1       bed1        bed_bath_table  01-06-2017         3       137.85   \n",
       "2       bed1        bed_bath_table  01-07-2017         6       275.70   \n",
       "3       bed1        bed_bath_table  01-08-2017         4       183.80   \n",
       "4       bed1        bed_bath_table  01-09-2017         2        91.90   \n",
       "\n",
       "   freight_price  unit_price  product_rating  no_customers  month  ...  \\\n",
       "0      15.100000       45.95             4.0            57      5  ...   \n",
       "1      12.933333       45.95             4.0            61      6  ...   \n",
       "2      14.840000       45.95             4.0           123      7  ...   \n",
       "3      14.287500       45.95             4.0            90      8  ...   \n",
       "4      15.100000       45.95             4.0            54      9  ...   \n",
       "\n",
       "   comp1_price  comp1_prod_rating  comp1_freight_price  comp2_price  \\\n",
       "0         89.9                3.9            15.011897   215.000000   \n",
       "1         89.9                3.9            14.769216   209.000000   \n",
       "2         89.9                3.9            13.993833   205.000000   \n",
       "3         89.9                3.9            14.656757   199.509804   \n",
       "4         89.9                3.9            18.776522   163.398710   \n",
       "\n",
       "   comp2_prod_rating  comp2_freight_price  comp3_price  comp3_prod_rating  \\\n",
       "0                4.4             8.760000        45.95                4.0   \n",
       "1                4.4            21.322000        45.95                4.0   \n",
       "2                4.4            22.195932        45.95                4.0   \n",
       "3                4.4            19.412885        45.95                4.0   \n",
       "4                4.4            24.324687        45.95                4.0   \n",
       "\n",
       "   comp3_freight_price  lag_price  \n",
       "0            15.100000      45.90  \n",
       "1            12.933333      45.95  \n",
       "2            14.840000      45.95  \n",
       "3            14.287500      45.95  \n",
       "4            15.100000      45.95  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "file_path = Path(\"Resources/retail_price_cleaned.csv\")\n",
    "df_sales = pd.read_csv(file_path)\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbffe52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dates into datetime for \"year\",\"month\",\"month_year\"\n",
    "df_sales['year'] = pd.to_datetime(df_sales['month_year'], format='%d-%m-%Y').dt.year \n",
    "df_sales['month'] = pd.to_datetime(df_sales['month_year'], format='%d-%m-%Y').dt.month\n",
    "df_sales['month_year'] = pd.to_datetime(df_sales['month_year'], format='%d-%m-%Y').dt.strftime('%Y-%m') #.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d599a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_copy = df_sales.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42bcf25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 25)                525       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 796\n",
      "Trainable params: 796\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = 25\n",
    "hidden_nodes_layer1 =  25\n",
    "hidden_nodes_layer2 = 10\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"relu\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14b91829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67029cf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/pfq_1hn94mq_0kn9gpm_dgj40000gp/T/ipykernel_67004/916530953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3689\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3690\u001b[0m             raise RuntimeError(\n\u001b[0;32m-> 3691\u001b[0;31m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3692\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3693\u001b[0m                 \u001b[0;34m\"Use `model.compile(optimizer, loss)`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the window size\n",
    "window_size = 5\n",
    "\n",
    "grouped = df_sales.groupby('product_id')\n",
    "\n",
    "table_data = []\n",
    "mse_scores = []\n",
    "predicted_unit_prices = []\n",
    "\n",
    "for group_key, group_data in grouped:\n",
    "    # set features and target variable\n",
    "    features = group_data[['qty_sold', 'total_price', 'freight_price', 'product_rating',\n",
    "                           'no_customers', 'seasonality', 'volume', 'comp1_price',\n",
    "                           'comp1_prod_rating', 'comp1_freight_price', 'comp2_price',\n",
    "                           'comp2_prod_rating', 'comp2_freight_price', 'comp3_price',\n",
    "                           'comp3_prod_rating', 'comp3_freight_price', 'lag_price']]\n",
    "\n",
    "    target = group_data['unit_price']\n",
    "    \n",
    "    num_samples = len(features)\n",
    "    predicted_unit_prices = []\n",
    "    \n",
    "    # sliding window training and testing\n",
    "    for i in range(window_size, num_samples):\n",
    "        # Define the periods for training and testing\n",
    "        train_start = i - window_size\n",
    "        train_end = i\n",
    "        test_start = i\n",
    "        test_end = i + 1\n",
    "        \n",
    "        # Split data into training and testing sets\n",
    "        features_train = features.iloc[train_start:train_end]\n",
    "        target_train = target.iloc[train_start:train_end]\n",
    "        features_test = features.iloc[test_start:test_end]\n",
    "        target_test = target.iloc[test_start:test_end]\n",
    "        \n",
    "        # Train the model\n",
    "        nn.fit(features_train,target_train,epochs=100)\n",
    "        # Make predictions\n",
    "        y_pred = nn.predict(features_test)\n",
    "        \n",
    "        # Evaluate using Mean Squared Error\n",
    "        mse = mean_squared_error(target_test, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "        \n",
    "        # Calculate and store the predicted unit prices\n",
    "        predicted_unit_price = y_pred[0]\n",
    "        predicted_unit_prices.append(predicted_unit_price)\n",
    "        \n",
    "        table_data.append([group_key, i+1, predicted_unit_price, mse])\n",
    "\n",
    "# Print table\n",
    "table_headers = [\"Product ID\", \"Sample\", \"Predicted Price\", \"MSE\"]\n",
    "print(tabulate(table_data, headers=table_headers, floatfmt=(\".0f\", \".0f\", \".2f\", \".2f\")))\n",
    "\n",
    "avg_mse = np.mean(mse_scores)\n",
    "avg_predicted_unit_price = np.mean(predicted_unit_prices)\n",
    "print(f\"Average MSE: {avg_mse:.2f}\")\n",
    "print(f\"Average Predicted Unit Price: {avg_predicted_unit_price:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25eab33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5579ecb6",
   "metadata": {},
   "source": [
    "## ML modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the features, X,  from the target variable, y\n",
    "y = df_sales_copy['quantity']\n",
    "X = df_sales_copy.drop(columns='quantity').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e0caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale\n",
    "\n",
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "# Transform the testing data using the scaler\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b87a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  50\n",
    "hidden_nodes_layer2 = 25\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"relu\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f442024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
